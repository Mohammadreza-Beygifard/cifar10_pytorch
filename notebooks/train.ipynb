{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d32f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:47:56.344696Z",
     "iopub.status.busy": "2023-11-05T08:47:56.344022Z",
     "iopub.status.idle": "2023-11-05T08:48:00.484196Z",
     "shell.execute_reply": "2023-11-05T08:48:00.483109Z",
     "shell.execute_reply.started": "2023-11-05T08:47:56.344663Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import torch.jit\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c150a",
   "metadata": {},
   "source": [
    "## Use GPU if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02374a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:48:01.529225Z",
     "iopub.status.busy": "2023-11-05T08:48:01.528645Z",
     "iopub.status.idle": "2023-11-05T08:48:01.535275Z",
     "shell.execute_reply": "2023-11-05T08:48:01.534244Z",
     "shell.execute_reply.started": "2023-11-05T08:48:01.529188Z"
    }
   },
   "outputs": [],
   "source": [
    "def choose_device() -> torch.device:\n",
    "    \"\"\" Move the device to GPU if it is supported by the OS \"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946ce53",
   "metadata": {},
   "source": [
    "### Check if GPU is available\n",
    "\n",
    "For MacOS GPU is available through Pytorch MPS and for Windows and linux it is available through Pytorch Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a8765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:48:02.493521Z",
     "iopub.status.busy": "2023-11-05T08:48:02.492730Z",
     "iopub.status.idle": "2023-11-05T08:48:05.617481Z",
     "shell.execute_reply": "2023-11-05T08:48:05.616450Z",
     "shell.execute_reply.started": "2023-11-05T08:48:02.493486Z"
    }
   },
   "outputs": [],
   "source": [
    "device = choose_device()\n",
    "print(device)\n",
    "x = torch.ones(1, device = device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ca97f",
   "metadata": {},
   "source": [
    "# Download and transform Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f6d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:48:06.935113Z",
     "iopub.status.busy": "2023-11-05T08:48:06.934277Z",
     "iopub.status.idle": "2023-11-05T08:48:14.778878Z",
     "shell.execute_reply": "2023-11-05T08:48:14.778010Z",
     "shell.execute_reply.started": "2023-11-05T08:48:06.935076Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def clip_to_01(img):\n",
    "    # Clip image pixel values to the range [0, 1]\n",
    "    return torch.clamp(img, 0, 1)\n",
    "    \n",
    "transform_primary = transforms.Compose([\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "original_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:50:23.256586Z",
     "iopub.status.busy": "2023-11-05T08:50:23.256228Z",
     "iopub.status.idle": "2023-11-05T08:50:23.966015Z",
     "shell.execute_reply": "2023-11-05T08:50:23.964991Z",
     "shell.execute_reply.started": "2023-11-05T08:50:23.256558Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26357c92",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "To increase the available images artificially we perform data augmentation and append the augmented images to the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e05655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:50:40.482990Z",
     "iopub.status.busy": "2023-11-05T08:50:40.482100Z",
     "iopub.status.idle": "2023-11-05T08:53:05.951780Z",
     "shell.execute_reply": "2023-11-05T08:53:05.950747Z",
     "shell.execute_reply.started": "2023-11-05T08:50:40.482958Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.9, 1.1), antialias=True),\n",
    "    transforms.GaussianBlur(kernel_size=3)\n",
    "])\n",
    "\n",
    "augmented_data = []\n",
    "\n",
    "for original_image, original_label in original_train_dataset:\n",
    "    augmented_data.append((transform_primary(original_image), original_label))\n",
    "    augmented_image = transform_augmentation(original_image)\n",
    "    augmented_data.append((transform_primary(augmented_image), original_label))\n",
    "\n",
    "    \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "train_dataset = CustomDataset(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d05b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:53:32.572913Z",
     "iopub.status.busy": "2023-11-05T08:53:32.572115Z",
     "iopub.status.idle": "2023-11-05T08:53:32.849534Z",
     "shell.execute_reply": "2023-11-05T08:53:32.848586Z",
     "shell.execute_reply.started": "2023-11-05T08:53:32.572878Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\" Augmented dataset size: {len(list(train_dataset))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2169a",
   "metadata": {},
   "source": [
    "### Inspect the training data\n",
    "\n",
    "show_image() method gets an image and its label to let you inspect the training data.\n",
    "\n",
    "You can comment transforms.Normalize and clip_to_01 in the Download and transform Train data cell to inspect the real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bb118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:53:34.436737Z",
     "iopub.status.busy": "2023-11-05T08:53:34.436034Z",
     "iopub.status.idle": "2023-11-05T08:53:34.443710Z",
     "shell.execute_reply": "2023-11-05T08:53:34.442786Z",
     "shell.execute_reply.started": "2023-11-05T08:53:34.436704Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_image(image : torch.tensor, label : int) -> None:\n",
    "    assert image.size(0) == 3, \"First dimension should present the three color channels\"\n",
    "    assert image.size(1) == 32, \"Expected a 32 * 32 image\"\n",
    "    assert image.size(2) == 32, \"Expected a 32 * 32 image\"\n",
    "\n",
    "    red_channel = image[0]\n",
    "    green_channel = image[1]\n",
    "    blue_channel = image[2]\n",
    "    print(f\"label: {label}\")\n",
    "    plt.figure(figsize=(0.75,0.5))\n",
    "    rgb_image = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81446123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:53:35.455409Z",
     "iopub.status.busy": "2023-11-05T08:53:35.454750Z",
     "iopub.status.idle": "2023-11-05T08:53:42.379642Z",
     "shell.execute_reply": "2023-11-05T08:53:42.378385Z",
     "shell.execute_reply.started": "2023-11-05T08:53:35.455375Z"
    }
   },
   "outputs": [],
   "source": [
    "original_train_dataset_list = list(original_train_dataset)\n",
    "print(f\"original_dataset size: {len(original_train_dataset_list)}\")\n",
    "# Change this index to inspect diffrent images\n",
    "index = 0\n",
    "image, label = original_train_dataset_list[index]\n",
    "show_image(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d30087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:53:44.846622Z",
     "iopub.status.busy": "2023-11-05T08:53:44.845755Z",
     "iopub.status.idle": "2023-11-05T08:53:45.162184Z",
     "shell.execute_reply": "2023-11-05T08:53:45.161113Z",
     "shell.execute_reply.started": "2023-11-05T08:53:44.846588Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_train_data_set_list = list(train_dataset)\n",
    "index = 9\n",
    "image, label = augmented_train_data_set_list[index]\n",
    "show_image(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa9968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:53:45.410162Z",
     "iopub.status.busy": "2023-11-05T08:53:45.409358Z",
     "iopub.status.idle": "2023-11-05T08:53:47.992034Z",
     "shell.execute_reply": "2023-11-05T08:53:47.990436Z",
     "shell.execute_reply.started": "2023-11-05T08:53:45.410128Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset_list = list(test_dataset)\n",
    "\n",
    "index = 3\n",
    "image, label = test_dataset_list[index]\n",
    "show_image(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73b3be",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "The Model that I used in this notebook is a three block VGG feel free to play with it, by adding or removing blocks, changing the dropout and what ever that can help you to explore more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c2165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T08:54:16.103680Z",
     "iopub.status.busy": "2023-11-05T08:54:16.103284Z",
     "iopub.status.idle": "2023-11-05T08:54:16.122290Z",
     "shell.execute_reply": "2023-11-05T08:54:16.121271Z",
     "shell.execute_reply.started": "2023-11-05T08:54:16.103645Z"
    }
   },
   "outputs": [],
   "source": [
    "class VGGThreeBlocks(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGGThreeBlocks, self).__init__()\n",
    "        \n",
    "        \n",
    "        # Convolutional layers\n",
    "        # VGG 1\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(32)\n",
    "        self.relu0 = nn.ReLU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # VGG 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # VGG 3\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "        self.dropout2 = nn.Dropout(0.8)\n",
    "        \n",
    "        # Batch normalization\n",
    "        \n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 1024)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.relu5 = nn.ReLU()  \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.predicator = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # VGG 1\n",
    "        x = self.relu0(self.bn0(self.conv0(x)))\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        # VGG 2\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        # VGG 3\n",
    "        x = self.relu4(self.bn4(self.conv4(x)))\n",
    "        x = self.pool5(self.relu5(self.bn5(self.conv5(x))))\n",
    "        \n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu4(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu5(self.fc2(x)))\n",
    "        x = self.relu6(self.fc3(x))\n",
    "        x = self.predicator(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def custom_weight_init(module):\n",
    "    \"\"\" You can initialize your model weights by a custom method \"\"\"\n",
    "    if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
    "        # Initialize weights using your custom logic\n",
    "        nn.init.xavier_normal_(module.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a22cc0",
   "metadata": {},
   "source": [
    "### A Method for drawing the loss function\n",
    "\n",
    "Drawing the loss function against the epochs can help you to get a feeling on how you are training your model and if you need to change some hyper parameter to train the model more effective.\n",
    "\n",
    "For example, if your loss function is not reducing \"almost\" monotonically, probably your learning rate is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b5805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:25:28.804408Z",
     "iopub.status.busy": "2023-11-05T09:25:28.803647Z",
     "iopub.status.idle": "2023-11-05T09:25:28.809847Z",
     "shell.execute_reply": "2023-11-05T09:25:28.808899Z",
     "shell.execute_reply.started": "2023-11-05T09:25:28.804376Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(loss : list, accuracy : list ,epochs : list):\n",
    "    plt.figure()\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(epochs, loss, color='blue', label='loss')\n",
    "    plt.plot(epochs, accuracy, color='green', label='accuracy')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db43a9e",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Here we are creating the model and applying the custom weight initialization. Feel free to use a different initialization technique or just comment the model.apply() method to go on with the torch default weight initialization.\n",
    "\n",
    "**state_dict_epoch** is used to save the sate of the model when the loss function is in its lowest value. This technique is called early drop.\n",
    "\n",
    "**number of epochs** is also defined in this cell. Change it based on your need, for example run the model for a single epoch to check if everything is working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e3016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:42:21.058250Z",
     "iopub.status.busy": "2023-11-05T09:42:21.057442Z",
     "iopub.status.idle": "2023-11-05T09:42:21.110572Z",
     "shell.execute_reply": "2023-11-05T09:42:21.109789Z",
     "shell.execute_reply.started": "2023-11-05T09:42:21.058215Z"
    }
   },
   "outputs": [],
   "source": [
    "#create or reset the model\n",
    "model = VGGThreeBlocks(num_classes=10)\n",
    "model.apply(custom_weight_init)\n",
    "\n",
    "state_dict_epoch = {\n",
    "    \"epoch\": 0,\n",
    "    \"loss\": 0,\n",
    "    \"state_dict\":{}\n",
    "}\n",
    "\n",
    "# This is used for drawing the loss against the epochs\n",
    "loss_list = []\n",
    "\n",
    "# This is used for calculating the acuracy throw training\n",
    "correct = 0\n",
    "total = 0\n",
    "accuracy_list = []\n",
    "\n",
    "# Use a single or low number of epochs for debuging purposes\n",
    "num_epochs = 10\n",
    "epochs = range(num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fa571",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "It is worth to mention that I use ExponentialLR scheduler to reduce the learning rate after each epoch to reduce the learning rate and avoid an unstable loss function behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792108d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:42:22.800846Z",
     "iopub.status.busy": "2023-11-05T09:42:22.800470Z",
     "iopub.status.idle": "2023-11-05T09:42:22.807218Z",
     "shell.execute_reply": "2023-11-05T09:42:22.806224Z",
     "shell.execute_reply.started": "2023-11-05T09:42:22.800814Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_state_epoch(epoch, loss_value, model_state, state_dict_epoch):\n",
    "    \"\"\"This method is used to capture the state when the loss has its minimum value\"\"\"\n",
    "    if(epoch == 0):   \n",
    "        state_dict_epoch[\"epoch\"] = epoch\n",
    "        state_dict_epoch[\"loss\"] = loss\n",
    "        state_dict_epoch[\"state_dict\"] = model_state\n",
    "    if(epoch > 1 and loss < state_dict_epoch[\"loss\"]):\n",
    "        state_dict_epoch[\"epoch\"] = epoch\n",
    "        state_dict_epoch[\"loss\"] = loss\n",
    "        state_dict_epoch[\"state_dict\"] = model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa021ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:42:23.478093Z",
     "iopub.status.busy": "2023-11-05T09:42:23.477205Z",
     "iopub.status.idle": "2023-11-05T09:59:01.396121Z",
     "shell.execute_reply": "2023-11-05T09:59:01.395148Z",
     "shell.execute_reply.started": "2023-11-05T09:42:23.478057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to(device) #Use GPU if it is available, check the first cell for more info\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.01)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.90)\n",
    "\n",
    "batch_size = 125\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the beta value for the EMA (usually a value close to 1, e.g., 0.9)\n",
    "beta = 0.9\n",
    "\n",
    "# Initialize the EMA loss\n",
    "ema_loss = None\n",
    "\n",
    "for epoch in epochs:\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    accuracy = correct / total\n",
    "    accuracy_list.append(accuracy)\n",
    "    # Calculate EMA loss\n",
    "    if ema_loss is None:\n",
    "        ema_loss = loss.item()\n",
    "    else:\n",
    "        ema_loss = beta * ema_loss + (1 - beta) * loss.item()\n",
    "    loss_list.append(ema_loss)\n",
    "    \n",
    "    update_state_epoch(epoch, loss.item(), model.state_dict(), state_dict_epoch)\n",
    "    \n",
    "    scheduler.step()\n",
    "    if((epoch +1)%(num_epochs / 5) == 0 or epoch == 0):    \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {loss.item():.4f} - Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\"\"Minimum loss has happened at epoch number {state_dict_epoch[\"epoch\"]}\"\"\")\n",
    "    \n",
    "plot_loss(loss_list, accuracy_list, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec55b4",
   "metadata": {},
   "source": [
    "## Save the trained model state\n",
    "\n",
    "Here I am dumping the model state in its lowest loss.\n",
    "\n",
    "feel free to change the first parameter with model.state_dict() to drop the model state at its latest state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb18c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T10:02:56.865615Z",
     "iopub.status.busy": "2023-11-05T10:02:56.864781Z",
     "iopub.status.idle": "2023-11-05T10:02:56.909579Z",
     "shell.execute_reply": "2023-11-05T10:02:56.908586Z",
     "shell.execute_reply.started": "2023-11-05T10:02:56.865570Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./model_state\"):\n",
    "    os.mkdir(\"./model_state\")\n",
    "    \n",
    "torch.save(state_dict_epoch[\"state_dict\"], \"./model_state/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa449189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:14:01.719304Z",
     "iopub.status.busy": "2023-11-05T09:14:01.718694Z",
     "iopub.status.idle": "2023-11-05T09:14:01.747519Z",
     "shell.execute_reply": "2023-11-05T09:14:01.746546Z",
     "shell.execute_reply.started": "2023-11-05T09:14:01.719271Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model_state/model.pt\"))\n",
    "model.eval() # To avoid dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509e0a8",
   "metadata": {},
   "source": [
    "# Evaluate the trained model\n",
    "\n",
    "Here we load the downloaded test data and evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c5021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:59:37.544247Z",
     "iopub.status.busy": "2023-11-05T09:59:37.543865Z",
     "iopub.status.idle": "2023-11-05T09:59:37.548961Z",
     "shell.execute_reply": "2023-11-05T09:59:37.548005Z",
     "shell.execute_reply.started": "2023-11-05T09:59:37.544217Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "validation_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d774e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T10:03:21.903339Z",
     "iopub.status.busy": "2023-11-05T10:03:21.902409Z",
     "iopub.status.idle": "2023-11-05T10:03:21.909616Z",
     "shell.execute_reply": "2023-11-05T10:03:21.908603Z",
     "shell.execute_reply.started": "2023-11-05T10:03:21.903304Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(torch.device(\"cpu\"))\n",
    "model.eval() # To avoid dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067238d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T10:03:22.213103Z",
     "iopub.status.busy": "2023-11-05T10:03:22.212723Z",
     "iopub.status.idle": "2023-11-05T10:04:49.888863Z",
     "shell.execute_reply": "2023-11-05T10:04:49.887380Z",
     "shell.execute_reply.started": "2023-11-05T10:03:22.213067Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in validation_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ce205",
   "metadata": {},
   "source": [
    "## Check the test and train data distribution\n",
    "\n",
    "Here we check the distribution of different labels in the test and train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb47def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T12:28:24.001602Z",
     "iopub.status.busy": "2023-11-01T12:28:24.001196Z",
     "iopub.status.idle": "2023-11-01T12:28:29.302343Z",
     "shell.execute_reply": "2023-11-01T12:28:29.301276Z",
     "shell.execute_reply.started": "2023-11-01T12:28:24.001569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get class distribution from a data loader\n",
    "def get_class_distribution(data_loader):\n",
    "    class_count = np.zeros(10)\n",
    "    for images, labels in data_loader:\n",
    "        class_count += np.bincount(labels, minlength=10)\n",
    "    return class_count\n",
    "\n",
    "# Get class distribution for train and test datasets\n",
    "train_class_distribution = get_class_distribution(train_loader)\n",
    "test_class_distribution = get_class_distribution(validation_loader)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(10), train_class_distribution, label='Train', alpha=0.7)\n",
    "plt.bar(range(10), test_class_distribution, label='Test', alpha=0.7)\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(range(10), ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
